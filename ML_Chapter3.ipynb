{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Notes (Chapter 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 公式3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\newcommand{\\myw}{\\hat{\\boldsymbol{w}}}\n",
    "\\myw^* = \\mathop{\\mathrm{argmin}} \\limits_{\\myw} \\left(\\boldsymbol{y} - \\mathbf{X}\\myw \\right)^T \\left(\\boldsymbol{y} - \\mathbf{X}\\myw \\right) \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 令$$ E_\\hat{\\boldsymbol{w}} = \\left(\\boldsymbol{y} - \\mathbf{X}\\myw \\right)^T \\left(\\boldsymbol{y} - \\mathbf{X}\\myw \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\newcommand{\\myw}{\\hat{\\boldsymbol{w}}}\n",
    "\\newcommand{\\myy}{\\boldsymbol{y}}\n",
    " \\frac{\\partial E_\\myw}{\\partial \\myw} &= \\frac{\\partial}{\\partial \\myw} \\left( \\myy^T \\myy - \\myy^T \\mathbf{X}\\myw - \\myw^T \\mathbf{X}^T\\myy + \\myw^T\\mathbf{X}^T \\mathbf{X}\\myw \\right) \\\\\n",
    "    &= -2 \\mathbf{X}^T y + 2 \\mathbf{X}^T \\mathbf{X}\\myw \\\\\n",
    "    &= 2 \\mathbf{X}^T \\left( \\mathbf{X}\\myw - \\myy \\right) \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这里用了两个矩阵求导的两个结论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\newcommand{\\myd}{\\mathrm{d}}\n",
    "\\newcommand{\\myx}{\\boldsymbol{X}}\n",
    "$\n",
    "> - 标量函数 $f(\\boldsymbol{X})=\\boldsymbol{A} \\myx $和梯度矩阵$\\nabla_\\myx f(\\boldsymbol{X})$之间的关系\n",
    "\n",
    "> $$\n",
    "\\myd f(\\myx) = tr(\\boldsymbol{A} \\myd \\myx) \\quad \\Longleftrightarrow \\quad \\nabla_\\myx f(\\myx) = \\boldsymbol{A}^T \\\\\n",
    "\\frac {\\partial f(\\myx)}{\\partial \\myx} = \\boldsymbol{A}^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\newcommand{\\myd}{\\mathrm{d}}\n",
    "\\newcommand{\\myx}{\\boldsymbol{X}}\n",
    "\\newcommand{\\mya}{\\boldsymbol{A}}\n",
    "$\n",
    "> - 标量函数 $f(\\boldsymbol{X})=\\myx^T \\mya \\myx  $和梯度矩阵$\\nabla_\\myx f(\\boldsymbol{X})$之间的关系\n",
    "\n",
    "> $$\n",
    "    \\frac{\\partial tr(\\myx^T \\mya \\myx)}{\\partial X} = \\left( \\mya + \\mya^T \\right) \\myx\n",
    "$$\n",
    "> 当$\\mya = \\myx^T \\myx$时，$ \\mya = \\mya^T$, 故 $\\mya + \\mya^T = 2 \\mya = 2 \\myx^T \\myx$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大似然方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大似然原理假定样本数据是群体$f_x(x_1, x_2, \\cdots, x_n; \\theta)$的一个代表，选择$\\theta$的值使得观测数据发生的可能性最大。即，一旦观测数据$x_1, x_2, \\cdots, x_n$ 给定，$f_x(x_1, x_2, \\cdots, x_n; \\theta)$仅仅是$\\theta$的函数，使得概率密度函数最大的$\\theta$值是$\\theta$的最可能的取值，它就是最大似然估计，记作$\\hat{\\theta_{ML}}(\\boldsymbol{x})$\n",
    "\n",
    "$$ \\hat{\\theta}_{ML} = \\mathop{\\mathrm{sup}} \\limits_{\\theta} f_x(x_1, x_2, \\cdots, x_n; \\theta)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
